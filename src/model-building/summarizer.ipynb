{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a08b81d",
   "metadata": {},
   "source": [
    "# Agenda:\n",
    "<ul>\n",
    "    <li>This file focuses on fine-tuning the Pre-trained Generative AI model T5-Small seq2seq Transformer model</li>\n",
    "    <li>The model has a Embedding + 6 encoder + 6 decoder + 1 LM (language Modelling) layer</li>\n",
    "    <li>Freezing the lower layer + 4 encoder and decoder layers each</li>\n",
    "    <li>Keeping the last layer for text summarization</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46502fb6",
   "metadata": {},
   "source": [
    "# Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94ef5f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Avik Chakraborty\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import polars\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from transformers import TFAutoModelForSeq2SeqLM, AutoTokenizer\n",
    "import numpy\n",
    "import datetime\n",
    "from evaluate import load\n",
    "import matplotlib.pyplot as mplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11d324e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>article</th><th>highlights</th></tr><tr><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;LONDON, England -- Harry Potte…</td><td>&quot;Harry Potter star Daniel Radcl…</td></tr><tr><td>&quot;Editor&#x27;s note: In our Behind t…</td><td>&quot;Mentally ill inmates in Miami …</td></tr><tr><td>&quot;MINNEAPOLIS, Minnesota (CNN) -…</td><td>&quot;NEW: &quot;I thought I was going to…</td></tr><tr><td>&quot;WASHINGTON (CNN) -- Doctors re…</td><td>&quot;Five small polyps found during…</td></tr><tr><td>&quot;(CNN) -- The National Football…</td><td>&quot;NEW: NFL chief, Atlanta Falcon…</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 2)\n",
       "┌─────────────────────────────────┬─────────────────────────────────┐\n",
       "│ article                         ┆ highlights                      │\n",
       "│ ---                             ┆ ---                             │\n",
       "│ str                             ┆ str                             │\n",
       "╞═════════════════════════════════╪═════════════════════════════════╡\n",
       "│ LONDON, England -- Harry Potte… ┆ Harry Potter star Daniel Radcl… │\n",
       "│ Editor's note: In our Behind t… ┆ Mentally ill inmates in Miami … │\n",
       "│ MINNEAPOLIS, Minnesota (CNN) -… ┆ NEW: \"I thought I was going to… │\n",
       "│ WASHINGTON (CNN) -- Doctors re… ┆ Five small polyps found during… │\n",
       "│ (CNN) -- The National Football… ┆ NEW: NFL chief, Atlanta Falcon… │\n",
       "└─────────────────────────────────┴─────────────────────────────────┘"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = polars.read_csv('../../datasets/Cleaned News dataset.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7abe4074",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>highlights</th><th>new_article</th></tr><tr><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;Harry Potter star Daniel Radcl…</td><td>&quot;summarize: LONDON, England -- …</td></tr><tr><td>&quot;Mentally ill inmates in Miami …</td><td>&quot;summarize: Editor&#x27;s note: In o…</td></tr><tr><td>&quot;NEW: &quot;I thought I was going to…</td><td>&quot;summarize: MINNEAPOLIS, Minnes…</td></tr><tr><td>&quot;Five small polyps found during…</td><td>&quot;summarize: WASHINGTON (CNN) --…</td></tr><tr><td>&quot;NEW: NFL chief, Atlanta Falcon…</td><td>&quot;summarize: (CNN) -- The Nation…</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 2)\n",
       "┌─────────────────────────────────┬─────────────────────────────────┐\n",
       "│ highlights                      ┆ new_article                     │\n",
       "│ ---                             ┆ ---                             │\n",
       "│ str                             ┆ str                             │\n",
       "╞═════════════════════════════════╪═════════════════════════════════╡\n",
       "│ Harry Potter star Daniel Radcl… ┆ summarize: LONDON, England -- … │\n",
       "│ Mentally ill inmates in Miami … ┆ summarize: Editor's note: In o… │\n",
       "│ NEW: \"I thought I was going to… ┆ summarize: MINNEAPOLIS, Minnes… │\n",
       "│ Five small polyps found during… ┆ summarize: WASHINGTON (CNN) --… │\n",
       "│ NEW: NFL chief, Atlanta Falcon… ┆ summarize: (CNN) -- The Nation… │\n",
       "└─────────────────────────────────┴─────────────────────────────────┘"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset.with_columns((\n",
    "    polars.lit('summarize: ') + polars.col('article')\n",
    "    ).\n",
    "    alias('new_article')\n",
    ").drop('article')\n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ca40a0",
   "metadata": {},
   "source": [
    "# Dataset Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8d76c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts, temp_texts, train_summaries, temp_summaries = train_test_split(\n",
    "    dataset['new_article'], dataset['highlights'], test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "val_texts, test_texts, val_summaries, test_summaries = train_test_split(\n",
    "    temp_texts, temp_summaries, test_size=0.5, random_state=42\n",
    ")\n",
    "\n",
    "del dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17aea926",
   "metadata": {},
   "source": [
    "# Tokenizing the data (On-the-fly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b141ebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Avik Chakraborty\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('t5-small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa540557",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('t5-small')\n",
    "\n",
    "# Parameters\n",
    "MAX_INPUT_LEN = 400\n",
    "MAX_TARGET_LEN = 100\n",
    "\n",
    "# Tokenization function\n",
    "def tf_tokenize(example_text, example_summary):\n",
    "    # Convert tf.Tensor to string in py_function\n",
    "    def tokenize_fn(text, summary):\n",
    "        text = text.decode('utf-8')\n",
    "        summary = summary.decode('utf-8')\n",
    "\n",
    "        inputs = tokenizer(\n",
    "            text,\n",
    "            max_length=MAX_INPUT_LEN,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors=None\n",
    "        )\n",
    "        targets = tokenizer(\n",
    "            summary,\n",
    "            max_length=MAX_TARGET_LEN,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors=None\n",
    "        )\n",
    "\n",
    "        return (\n",
    "            tf.convert_to_tensor(inputs['input_ids'], dtype=tf.int32),\n",
    "            tf.convert_to_tensor(inputs['attention_mask'], dtype=tf.int32),\n",
    "            tf.convert_to_tensor(targets['input_ids'], dtype=tf.int32)\n",
    "        )\n",
    "\n",
    "    input_ids, attention_mask, labels = tf.py_function(\n",
    "        tokenize_fn,\n",
    "        [example_text, example_summary],\n",
    "        [tf.int32, tf.int32, tf.int32]\n",
    "    )\n",
    "\n",
    "    # Set shapes explicitly for performance and compatibility\n",
    "    input_ids.set_shape([MAX_INPUT_LEN])\n",
    "    attention_mask.set_shape([MAX_INPUT_LEN])\n",
    "    labels.set_shape([MAX_TARGET_LEN])\n",
    "\n",
    "    return {'input_ids': input_ids, 'attention_mask': attention_mask}, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51824e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tf_dataset(inputs, targets, batch_size=4):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((inputs, targets))\n",
    "    dataset = dataset.map(tf_tokenize, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    dataset = dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c54be2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets for model\n",
    "# Build on On-the-fly mode\n",
    "train_dataset = create_tf_dataset(list(train_texts), list(train_summaries))\n",
    "val_dataset = create_tf_dataset(list(val_texts), list(val_summaries))\n",
    "test_dataset = create_tf_dataset(list(test_texts), list(test_summaries))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cffc1c50",
   "metadata": {},
   "source": [
    "# Model Building\n",
    "## Downloading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9a63e9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Avik Chakraborty\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFT5ForConditionalGeneration.\n",
      "\n",
      "All the weights of TFT5ForConditionalGeneration were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "t5_model = TFAutoModelForSeq2SeqLM.from_pretrained('t5-small')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3434ee",
   "metadata": {},
   "source": [
    "## Customizing the model\n",
    "<ul>\n",
    "    <li>Customizin the model layer's to be trained and left frozen</li>\n",
    "    <li>Setting the embedding + lower 4 encoder, decoder (each) layers frozen</li>\n",
    "    <li>Keeping the last 2 encoder decoder (each) layer + LM layer as trainable</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9c00886",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze embeddings\n",
    "t5_model.shared.trainable = False\n",
    "t5_model.encoder.embed_tokens.trainable = False\n",
    "t5_model.decoder.embed_tokens.trainable = False\n",
    "\n",
    "# Freeze lower 4 encoder layers (0 to 3)\n",
    "for i, layer in enumerate(t5_model.encoder.block):\n",
    "    if i < 4:\n",
    "        layer.trainable = False\n",
    "    else:\n",
    "        layer.trainable = True\n",
    "\n",
    "# Freeze lower 4 decoder layers (0 to 3)\n",
    "for i, layer in enumerate(t5_model.decoder.block):\n",
    "    if i < 4:\n",
    "        layer.trainable = False\n",
    "    else:\n",
    "        layer.trainable = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf1afdd",
   "metadata": {},
   "source": [
    "## Setting up model callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1bf0047a",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "# Early Stopping\n",
    "early_stopping_monitor = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',         # Monitor the validation loss\n",
    "    patience=3,                 # Number of epochs with no improvement after which training will be stopped\n",
    "    restore_best_weights=True,  # Restore model weights from the epoch with the best value of the monitored quantity\n",
    "    min_delta=1e-4              # Counts the minimum change as viable change in loss\n",
    ")\n",
    "\n",
    "# Model Checkpoint to save data\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=f'../../models/best_model_{timestamp}_epoch-{{epoch:02d}}_val_loss-{{val_loss:.4f}}.keras', # Filepath to save the model weights\n",
    "    monitor='val_loss',         # Metric to monitor\n",
    "    save_best_only=True,        # Only save when the monitored metric is the best seen so far\n",
    "    save_weights_only=False,    # Save the entire model\n",
    "    mode='min',                 # The monitored metric ('val_loss') should be minimized\n",
    "    verbose=1                   # Print a message when a checkpoint is saved\n",
    ")\n",
    "\n",
    "# Reducing Learning Rate On Plateau stage\n",
    "# Reducing learning rate if validation loss plateaus\n",
    "reduce_lr_on_plateau = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',         # Monitor the validation loss\n",
    "    factor=0.5,                 # Factor by which the learning rate will be reduced. new_lr = lr * factor\n",
    "    patience=2,                 # Number of epochs with no improvement after which the learning rate will be reduced\n",
    "    mode='min',                 # The monitored metric ('val_loss') should be minimized\n",
    "    verbose=1,                  # Print a message when the learning rate is reduced\n",
    "    min_lr=1e-5,                # Lower bound on the learning rate\n",
    "    min_delta=1e-4              # Counts the minimum change as viable change\n",
    ")\n",
    "\n",
    "# Logging all metrics in a csv file for future use\n",
    "csv_logger = tf.keras.callbacks.CSVLogger(\n",
    "    filename=f'../../logs/training_log_{timestamp}.csv',\n",
    "    append=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4949d3d",
   "metadata": {},
   "source": [
    "## Compiling model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "41243b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "t5_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=3e-5)     # Optimizer with the initial Learning Rate\n",
    "    #loss=t5_model.compute_loss                                  # T-5 seq2seq built in loss function\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c1da51fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tft5_for_conditional_generation\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " shared (Embedding)          multiple                  16449536  \n",
      "                                                                 \n",
      " encoder (TFT5MainLayer)     multiple                  35330816  \n",
      "                                                                 \n",
      " decoder (TFT5MainLayer)     multiple                  41625344  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 60506624 (230.81 MB)\n",
      "Trainable params: 14686208 (56.02 MB)\n",
      "Non-trainable params: 45820416 (174.79 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "t5_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f035240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "WARNING:tensorflow:From c:\\Users\\Avik Chakraborty\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "Graph execution error:\n\nDetected at node EagerPyFunc defined at (most recent call last):\n<stack traces unavailable>\nAttributeError: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'decode'\nTraceback (most recent call last):\n\n  File \"c:\\Users\\Avik Chakraborty\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 268, in __call__\n    return func(device, token, args)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"c:\\Users\\Avik Chakraborty\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 146, in __call__\n    outputs = self._call(device, args)\n              ^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"c:\\Users\\Avik Chakraborty\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 153, in _call\n    ret = self._func(*args)\n          ^^^^^^^^^^^^^^^^^\n\n  File \"c:\\Users\\Avik Chakraborty\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n\n  File \"C:\\Users\\AVIKCH~1\\AppData\\Local\\Temp\\__autograph_generated_file_p2n02_y.py\", line 16, in tokenize_fn\n    text = ag__.converted_call(ag__.ld(text).decode, ('utf-8',), None, fscope_1)\n                               ^^^^^^^^^^^^^^^^^^^^\n\n  File \"c:\\Users\\Avik Chakraborty\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\framework\\tensor.py\", line 261, in __getattr__\n    self.__getattribute__(name)\n\nAttributeError: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'decode'\n\n\n\t [[{{node EagerPyFunc}}]]\n\t [[IteratorGetNext]] [Op:__inference_train_function_22735]",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mUnknownError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m history = \u001b[43mt5_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_checkpoint_callback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m        \u001b[49m\u001b[43mearly_stopping_monitor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreduce_lr_on_plateau\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcsv_logger\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Avik Chakraborty\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     67\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m     68\u001b[39m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m     69\u001b[39m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m70\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     71\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     72\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Avik Chakraborty\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[39m, in \u001b[36mquick_execute\u001b[39m\u001b[34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     52\u001b[39m   ctx.ensure_initialized()\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m   tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[32m     54\u001b[39m                                       inputs, attrs, num_outputs)\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     56\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mUnknownError\u001b[39m: Graph execution error:\n\nDetected at node EagerPyFunc defined at (most recent call last):\n<stack traces unavailable>\nAttributeError: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'decode'\nTraceback (most recent call last):\n\n  File \"c:\\Users\\Avik Chakraborty\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 268, in __call__\n    return func(device, token, args)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"c:\\Users\\Avik Chakraborty\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 146, in __call__\n    outputs = self._call(device, args)\n              ^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"c:\\Users\\Avik Chakraborty\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 153, in _call\n    ret = self._func(*args)\n          ^^^^^^^^^^^^^^^^^\n\n  File \"c:\\Users\\Avik Chakraborty\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n\n  File \"C:\\Users\\AVIKCH~1\\AppData\\Local\\Temp\\__autograph_generated_file_p2n02_y.py\", line 16, in tokenize_fn\n    text = ag__.converted_call(ag__.ld(text).decode, ('utf-8',), None, fscope_1)\n                               ^^^^^^^^^^^^^^^^^^^^\n\n  File \"c:\\Users\\Avik Chakraborty\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\framework\\tensor.py\", line 261, in __getattr__\n    self.__getattribute__(name)\n\nAttributeError: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'decode'\n\n\n\t [[{{node EagerPyFunc}}]]\n\t [[IteratorGetNext]] [Op:__inference_train_function_22735]"
     ]
    }
   ],
   "source": [
    "history = t5_model.fit(\n",
    "    train_dataset, validation_data=val_dataset,\n",
    "    epochs=5,\n",
    "    callbacks=[\n",
    "        model_checkpoint_callback,\n",
    "        early_stopping_monitor,\n",
    "        reduce_lr_on_plateau,\n",
    "        csv_logger\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f98d71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
